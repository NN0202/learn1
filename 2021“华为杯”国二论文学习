#前两问：QSAR模型，建立分子描述符-化合物生物活性预测模型；后两问：建立化合物-药代动力学性质和安全性ADMET预测模型
#第一问：特征选择
#①数据预处理：清除缺失值、重复值、无关值、异常值/离群点、噪音点（随机误差）、方差过滤、3σ原则
  #无缺失值，用可视化矩阵展示
  #有一列重复值，分析代表的生物化学意义，以及对论文研究目的的作用，最终决定清除
  #0-1归一化处理：将数据的数值范围调整到一个特定的区间，公式：norm= (X−X min)/(Xmax−X min)
    import numpy as np
    import pandas as pd
    df = pd.DataFrame({ 'feature': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]})
    df['normalized_feature'] = (df['feature'] - df['feature'].min()) / (df['feature'].max() - df['feature'].min())
    # 设置阈值
    lower_threshold = 0.1
    upper_threshold = 0.9
    # 过滤掉偏离过大的数据
    df_filtered = df[(df['normalized_feature'] >= lower_threshold) & (df['normalized_feature'] <= upper_threshold)]
    print(df_filtered)

    # 设置方差阈值
    variance_threshold = 0.5
    # 计算每个特征的方差
    variances = df.var()
    # 找出方差大于阈值的特征
    selected_features = variances[variances > variance_threshold].index
    df_selected = df[selected_features]
#②特征选择算法
  #1.决策树：{用于分类和回归任务。它的工作原理是在每个节点选择一个特征进行分割，
  特征选择的常用标准有：信息增益（ID3算法）、增益率（C4.5算法）和基尼不纯度（ CART 算法）将数据分割成不同的组，直到达到某个条件或结果。逻辑上：多个if-else}
  
  #解决回归例子：
  from sklearn.datasets import make_regression
  from sklearn.model_selection import train_test_split
  from sklearn.tree import DecisionTreeRegressor
  from sklearn.metrics import mean_squared_error
  X, y = make_regression(n_samples=1000, n_features=1, noise=0.1)
  # 划分训练集和测试集
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
  # 创建决策树回归器实例
  regressor = DecisionTreeRegressor(random_state=42)
  # 训练模型
  regressor.fit(X_train, y_train)
  # 预测测试集
  y_pred = regressor.predict(X_test)
  # 计算均方误差
  mse = mean_squared_error(y_test, y_pred)
  print(f'Mean Squared Error: {mse}')
  
  #解决分类例子：
  from sklearn.tree import DecisionTreeClassifier
  clf = DecisionTreeClassifier(random_state=42)
  clf.fit(X_train, y_train)
  y_pred = clf.predict(X_test)
  print(classification_report(y_test, y_pred, target_names=iris.target_names))
 
  #2.梯度回升决策树LightGBM
  #3.XGBoost
  #4.重要性排序PI算法

#第二问：QSAR预测模型建立
  #①bp神经网络：类似于人的神经元，分为输入、隐藏、输出层，每一层神经元通过一些权重与其他层的神经元连接。
          步骤：初始参数-前向传播-计算损失函数：根据预测值和实际值计算损失函数的值-反向传播：根据损失函数的梯度，从输出层向输入层逐层计算各层参数的梯度
          -更新参数：根据计算出的梯度，使用优化算法（如梯度下降法）更新网络参数。-重复步骤2-5，直到满足停止条件（如达到最大迭代次数或损失函数收敛）。
          可以解决：分类、回归、时间序列、聚类等预测问题和优化问题，适用于数据较多
  #②svm支持向量机：核心目标是找到一个决策边界（或超平面），这个边界能够在不同类别的数据之间最大化间隔。
                  在二分类问题中，SVM试图找到一个超平面，使得两个类别之间的距离（即间隔）最大。
                  支持向量是指那些位于最大间隔边界上的数据点。这些数据点是定义决策边界的关键点，因为它们是距离超平面最近的点。如果这些点发生移动，超平面的位置也会随之改变。
                  用于解决二分类、多分类、回归等预测类问题，适用于小样本数据
  #③线性回归
  #④LightGBM
​	
